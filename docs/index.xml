<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Something I learned</title>
        <link>https://Ahmad-Zaki.github.io/</link>
        <description>Something I learned</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>ahmadheshamzaki@gmail.com (Ahmad Zaki)</managingEditor>
            <webMaster>ahmadheshamzaki@gmail.com (Ahmad Zaki)</webMaster><lastBuildDate>Tue, 30 Nov 2021 16:46:33 &#43;0200</lastBuildDate>
            <atom:link href="https://Ahmad-Zaki.github.io/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Regularizationمن الـ Biasلماذا نستثني الـ</title>
    <link>https://Ahmad-Zaki.github.io/%D9%84%D9%85%D8%A7%D8%B0%D8%A7-%D9%86%D8%B3%D8%AA%D8%AB%D9%86%D9%8A-%D8%A7%D9%84%D9%80bias-%D9%85%D9%86-%D8%A7%D9%84%D9%80regularization/</link>
    <pubDate>Tue, 30 Nov 2021 16:46:33 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://Ahmad-Zaki.github.io/%D9%84%D9%85%D8%A7%D8%B0%D8%A7-%D9%86%D8%B3%D8%AA%D8%AB%D9%86%D9%8A-%D8%A7%D9%84%D9%80bias-%D9%85%D9%86-%D8%A7%D9%84%D9%80regularization/</guid>
    <description><![CDATA[<div dir="rtl">
    <h4>
        الـregularization هو أحد الحلول الشائعة لمشكلة الـoverfitting، بيتم عن طريق إضافة penalty مباشرة على الـparameters في الـcost function عشان أقلل الـmodel complexity، لكن لو لاحظت هتلاقي إن الـbias مش موجود في الـpenalty دى على الرغم من إنه أحد الـparameters الى الموديل بيتعلمها، ايه السبب؟
    </h4>
</div>]]></description>
</item><item>
    <title>؟Imbalanced Datasets كيف نتعامل مع</title>
    <link>https://Ahmad-Zaki.github.io/imbalanced-datasets-%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9/</link>
    <pubDate>Sat, 20 Nov 2021 21:05:36 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://Ahmad-Zaki.github.io/imbalanced-datasets-%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9/</guid>
    <description><![CDATA[<div dir="rtl">
    <h4>
        من المشاكل الى قابلتها في الكورسات إن الـdataset أحياناً بتكون خالية من العيوب الى ممكن نلاقيها في أرض الواقع، وفي مجال الـclassification، فيه فرصة كبيرة إننا نتعامل مع imbalanced datasets لإن الأكيد إن مش كل الـclasses بتحدث بنفس النسبة وبالتالي الغير طبيعي هو إن لما أجمع data أشوف كل الـclasses بنفس الrate ، لكن ليه الـimbalance ده ممكن يسبب مشكلة أصلا؟
    </h4>
</div>]]></description>
</item><item>
    <title>؟Activation functionsالخيار الشائع للـ ReLUليه أصبحت الـ</title>
    <link>https://Ahmad-Zaki.github.io/%D9%84%D9%8A%D9%87-%D8%A3%D8%B5%D8%A8%D8%AD%D8%AA-%D8%A7%D9%84%D9%80relu-%D8%A7%D9%84%D8%AE%D9%8A%D8%A7%D8%B1-%D8%A7%D9%84%D8%B4%D8%A7%D8%A6%D8%B9-%D9%84%D9%84%D9%80activation-function/</link>
    <pubDate>Sat, 13 Nov 2021 11:11:45 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://Ahmad-Zaki.github.io/%D9%84%D9%8A%D9%87-%D8%A3%D8%B5%D8%A8%D8%AD%D8%AA-%D8%A7%D9%84%D9%80relu-%D8%A7%D9%84%D8%AE%D9%8A%D8%A7%D8%B1-%D8%A7%D9%84%D8%B4%D8%A7%D8%A6%D8%B9-%D9%84%D9%84%D9%80activation-function/</guid>
    <description><![CDATA[<div dir="rtl">
    <h4>
        ReLU هو اختصار Rectified Linear Unit وهي واحدة من أكثر الـactivation functions المستخدمة في الـNeural networks، رغم إن اسمها يحتوى على كلمة linear لكنها non linear function، وده واضح رياضياً وحتى من الرسم بتاعها، لكن ليه بتقدر تنافس الـactivation functions الأخرى المكوّنة من smooth curves رغم إنها حرفياً عبارة عن خطين بس؟
    </h4>
</div>]]></description>
</item><item>
    <title>؟Neural networksفي الـ Non-linear activation functions ليه بنحتاج</title>
    <link>https://Ahmad-Zaki.github.io/%D9%84%D9%8A%D9%87-%D8%A8%D9%86%D8%AD%D8%AA%D8%A7%D8%AC-non-linear-activation-functions-%D9%81%D9%8A-%D8%A7%D9%84%D9%80neural-networks/</link>
    <pubDate>Tue, 09 Nov 2021 13:08:51 &#43;0200</pubDate>
    <author>Author</author>
    <guid>https://Ahmad-Zaki.github.io/%D9%84%D9%8A%D9%87-%D8%A8%D9%86%D8%AD%D8%AA%D8%A7%D8%AC-non-linear-activation-functions-%D9%81%D9%8A-%D8%A7%D9%84%D9%80neural-networks/</guid>
    <description><![CDATA[<div dir="rtl">
    <h4>
        الهدف النهائي الى أنا عايزه من الـneural network هو انها تعبر بشكل تقريبي عن العلاقة ما بين $input \hspace{1mm} (X)$  و $target$ او $output \hspace{1mm} (y)$، بمعنى آخر أنا عايزها تـapproximate دالة $f$ حيث $f(x)=y$.
    </h4>
</div>]]></description>
</item></channel>
</rss>
