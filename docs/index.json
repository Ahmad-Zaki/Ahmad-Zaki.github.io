[{"categories":["مما تعلمت"],"content":" Naive Bayes Classifier هو أحد أنواع الـprobabilistic classifiers ومبني على تطبيق بسيط ومباشر لأحد أهم نظريات الاحتمالات: Bayes theorem. ورغم إنه يضع افتراض بسيط وفي الغالب غير مناسب للـdata لكنه سريع ومرن وبيقدم نتائج جيدة ويستخدم في الكثير من التطبيقات كـbaseline. لكن إزاي ممكن نستخدم Bayes theorem في الـclassification؟ لنفترض إن X عبارة data point، وإن X ممكن تنتمي لواحد من 2 classes وهم$y_{1}, y_{2}$ ، ممكن خلال Bayes theorem أقدر أحسب احتمال أن X تنتمي لـ$y_{1}$ واحتمال انها تنتمي لـ $y_{2}$ كالآتي: $$ P(y_{1}|X) = \\frac{P(X|y_{1})×P(y_{1})}{P(X)}, \\hspace{5mm} P(y_{2}|X) = \\frac{P(X|y_{2})×P(y_{2})}{P(X)} $$ الفكرة الرئيسية في Bayes theorem هي إنك من الـdata بتبني اعتقاد مبدأي (Prior Belief) عن كل class، بعد كده لما تشوف data points (Evidence) هتغير من اعتقادك المبدأي للاعتقاد جديد (Posterior Belief) وذلك بناء على مدى صحة الـevedence (Likelihood). إزاي بيحصل الكلام ده؟ في البداية أول معلومة تقدر تتعلمها من الـdata هي احتمال ظهور كل class في الداتا $P(y_{1}),P(y_{2})$، وهو ده الـprior belief: إحتمال إن أي data point تنتمي للـclass الأول أو الثاني، والفكرة منه هي إن يبقى عندك اعتقاد مبدأي عن احتمال انتماء data point معينة لأي class قبل ما تعرف أي تفاصيل عن الـdata point دى. خلينا نطرحها بمثال: لنفترض إننا بنحاول نفرق بين الـspam emails والـvalid emails، لما بصيت على الـdata لقيت إن 80% منها عبارة عن valid emails و 20% عبارة عن spam email. دلوقتي لو سألتك عن احتمال إن رسالة معينة تكون spam، بدون معرفة أي تفاصيل عن الرسالة، مش هتقدر تحكم عليها غير بالاعتقاد المبدأي الى كونته من الـdata المتاحة، وهو ده الـprior belief (P(spam)). لكن لو بدأت اديلك بعض المعلومات (features) عن الرسالة، زى بعض الكلمات الموجودة في الرسالة أو مصدرها، هتبدأ تغير اعتقادك المبدأي، لإنك لقيت evidence يرجح كفة class عن الأخرى، لتصل إلى اعتقاد جديد (Posterior belief P(spam|features)). لكن بأي نسبة هيتغير اعتقادك الجديد عن اعتقادك المبدأي؟ هيتغير بنسبة مدى صحة الـevidence على اعتبار إن الرسالة دى فعلا spam. وده ما يسمى بالـlikelihood (P(features|spam)). Fig 1: Bayes Rule Explained Source: Click here بناء على المثال ده، نقدر نمثل Bayes Rule بالمعادلة التالية: $$ Posterior = \\frac{Likelihood×Prior}{Evidence} $$ حتى الآن كل الى عملناه هو تطبيق Bayes Rule بشكل مباشر، الخطوة التالية هى إننا نحسب كل term في المعادلة عشان نقدر نحسب الـposterior ونوصل لنتيجة. الـPrior هو أسهل حاجة نقدر نحسبها في المعادلة، لإنه عبارة عن نسبة الـclass في الـdata، بالإضافة إلى إن لو عندك domain knowledge عن المشكلة قبل ما تبدأ تحلها، ممكن تستخدمها في إنك تحدد الـprior بنفسك. بالنسبة للـ likelihood ($P(y_{k}|X)$) فهنا لازم ناخد في الاعتبار إن X عبارة عن data point فيها أكتر من feature, بمعنى إن $X= (x_{1}, x_{2}, ...,x_{n})$ وبالتالي هنحسب $P(y_{k}|x_{1}, x_{2}, ...,x_{n})$. عشان نحسب الـterm هنستغل إننا نقدر نعبّر عن البسط كالآتي: $$ P(y_{k}|x_{1}, x_{2}, ...,x_{n})P(y_{k}) = P(y_{k},x_{1}, x_{2}, ...,x_{n}) $$ حيث أن $P(y_{k},x_{1}, x_{2}, ...,x_{n})$ تعبر عن الـjoint probability distribution بين الـclass وكل feature في الـdatapoint، من خلال الـdistribution ده ممكن نرتب الـvariables ونفكه من جديد باستخدام سلسلة من الـconditional probabilities: $$ P(x_{1}, x_{2}, ...,x_{n},y_{k}) = P(x_{1}| x_{2}, ...,x_{n},y_{k}) P(x_{2}, ...,x_{n},y_{k}) \\hspace{70mm} \\\\ \\rule{0mm}{5mm} \\hspace{6mm} = P(x_{1}| x_{2}, ...,x_{n},y_{k}) P(x_{2}| x_{3}, ...,x_{n},y_{k}) P(x_{3}, ...,x_{n},y_{k})\\\\ \\rule{0mm}{5mm} = ... \\hspace{70mm} \\\\ \\rule{0mm}{5mm} \\hspace{28mm}= P(x_{1}| x_{2}, ...,x_{n},y_{k}) P(x_{2}| x_{3}, ...,x_{n},y_{k})... P(x_{n-1}|x_{n},y_{k}) P(x_{n}|y_{k})P(y_{k}) $$ دلوقتي عندنا أكتر من conditional probability term بين كل الـfeatures وبعضها بالإضافة للـclass كمان، هنحسبهم كلهم إزاي؟ Naive Bayes بيضع افتراض بسيط جداً عشان يحل المشكلة دى: بيفترض إن الـfeatures مستقلة عن بعضها، بمعني إن مفيش أي علاقة تربط كل feature بالآخرى. الإفتراض الساذج ده هو سبب تسميته بـNaive classifier، لإنه لا يضع اعتبار للعلاقة بين كل feature والأخرى. لكنه بيبسّط المعادلة السابقة للشكل ده: $$ P(x_{1}, x_{2}, ...,x_{n},y_{k}) = P(x_{1}|\\cancel{ x_{2}, ...,x_{n}},y_{k}) P(x_{2}| \\cancel{x_{3}, ...,x_{n}},y_{k})... ","date":"2022-03-22","objectID":"/%D9%83%D9%8A%D9%81-%D9%8A%D8%B9%D9%85%D9%84-naive-bayes-classifier/:0:0","tags":["Machine Learning","Classification","Bayes Theorem","Naive Bayes Classifier","Data Science"],"title":"؟Naive Bayes Classifier كيف يعمل","uri":"/%D9%83%D9%8A%D9%81-%D9%8A%D8%B9%D9%85%D9%84-naive-bayes-classifier/"},{"categories":["مما تعلمت"],"content":" في الغالب كانت بداية معرفتك بالـbackbropagation عن طريق شرحه على Fully connected neural network, لكن بعد ما تتطرق لأشكال أخرى من الـneural netowrks مثل الـconvolutional neural network بتلاقي إن الـbackpropagation مستخدم فيهم كـalgorithm رئيسي لحساب الـgradients في كل layer لكن بدون ذكر تفاصيل أكثر عنها، لإنك بالفعل غير مضطر لمعرفة تفاصيل الرياضية قبل استخدامها، ومع ذلك فمعرفة كيف تتم داخل الـConv layers قد يكون سؤال مر ببالك ولو من باب الفضول في وقت من الأوقات. Note\r\rجميع الصور والـAnimation مصدرها هو المقال الرائع ده والى بيتكلم عن الـbackpropagation في الـconvnets بشكل مبسط وجيد جداً، أنصح بقراءته لمزيد من التفاصيل.\r\r Tip\r\rيفضّل أن يكون لديك معرفة كافية بخطوات الـbackpropagation واستخدام الـderivatives والـchain rule فيه قبل قراءة المقال.\r\r إذاً كيف يتم تنفيذ الـBackpropagation في الـConvNets؟ لنفترض إن عندنا Input $X_{3×3}$ و Filter $F_{2×2}$ كالتالي: $$X_{3×3} = \\left( \\begin{array}{ccc} X_{11}\u0026X_{12}\u0026X_{13} \\\\ X_{21}\u0026X_{22}\u0026X_{23} \\\\ X_{31}\u0026X_{32}\u0026X_{33} \\\\ \\end{array} \\right) \\hspace{10mm} F_{2×2} = \\left( \\begin{array}{cc} F_{11}\u0026F_{12} \\\\ F_{21}\u0026F_{22} \\\\ \\end{array} \\right) $$ في الـforward pass نحصل على ناتج الـconvolution بين $X$ و $F$ (على اعتبار ان الـstride=1 ,والـpadding=0) وهو $O_{2×2}$ ،و تتم العملية كالتالي: $$\\underbrace{\\left( \\begin{array}{cc} O_{11}\u0026O_{12} \\\\ O_{21}\u0026O_{22} \\\\ \\end{array} \\right)}_{O_{2×2}} = \\underbrace{\\left( \\begin{array}{ccc} X_{11}\u0026X_{12}\u0026X_{13} \\\\ X_{21}\u0026X_{22}\u0026X_{23} \\\\ X_{31}\u0026X_{32}\u0026X_{33} \\\\ \\end{array} \\right)}_{X_{3×3}} \\otimes \\underbrace{\\left( \\begin{array}{cc} F_{11}\u0026F_{12} \\\\ F_{21}\u0026F_{22} \\\\ \\end{array} \\right)}_{F_{2×2}} $$ Fig 1: Forward pass in a convolution layer with one filter عملية الـBackpropagation (موضّحة في Fig 2) تتم عن طريق الـChain rule، بنبدأ من آخر layer ونحسب الـloss gradient $\\frac{\\partial L}{\\partial z}$ بتاعها ونتحرك للـlayer الى قبلها. في الlayer التالية بنحسب الـloss gradient عندها عن طريق ضرب $\\frac{\\partial L}{\\partial z}$ في الـlocal gradients الخاصة بالـlayer وهي كل من $\\frac{\\partial z}{\\partial x}$ و $\\frac{\\partial z}{\\partial y}$. Fig 2: Gradients flow in a neuron في الـfully connected neural network، حساب الـlocal gradients يتم بطريقة مباشرة لأن z عبارة عن دالة في كل من x,y، لكن في الـconvolutional neural network نجد أن O عبارة عن ناتج convolution بين الـweights (الـfilter parameters) والfeature map X. Fig 3: Gradients flow in a convolutional neuron ليه بنحتاج نحسب الـlocal gradients في الـconvolution؟ $\\frac{\\partial O}{\\partial F}$ بنستخدمه عشان نحسب الـloss gradient بالنسبة لـF، وهو ده الى بنستخدمه عشان نعمل update لقيم الـfilter: $$ \\frac{\\partial L}{\\partial F} = \\frac{\\partial O}{\\partial F} × \\frac{\\partial L}{\\partial O} \\\\ \\rule{0mm}{7mm} F_{updated} = F - \\alpha \\frac{\\partial L}{\\partial F} $$ أما بالنسبة لـ $\\frac{\\partial O}{\\partial X}$، بما أن X هى output الـlayer السابقة، إذاً يصبح$\\frac{\\partial L}{\\partial X}$ هو الـloss gradient الخاص بالـlayer السابقة، وبالتالي بنحسبه عشان نكمل الـbackpropagation في باقي الـlayers. $$ \\frac{\\partial L}{\\partial X} = \\frac{\\partial O}{\\partial X} × \\frac{\\partial L}{\\partial O} $$ Fig 4: Why do we need to calculate $\\frac{\\partial L}{\\partial X}, \\frac{\\partial L}{\\partial F}$ إزاي هنحسب $\\frac{\\partial L}{\\partial F}$؟ في البداية عشان نحسب $\\frac{\\partial L}{\\partial F}$، هنحتاج نحسب الـlocal gradient الخاص بيها وهو $\\frac{\\partial O}{\\partial F}$، العلاقة بين O و F الى هنحسب منها الـgradient هى: $$\\underbrace{\\left( \\begin{array}{cc} O_{11}\u0026O_{12} \\\\ O_{21}\u0026O_{22} \\\\ \\end{array} \\right)}_{O_{2×2}} = \\underbrace{\\left( \\begin{array}{ccc} X_{11}\u0026X_{12}\u0026X_{13} \\\\ X_{21}\u0026X_{22}\u0026X_{23} \\\\ X_{31}\u0026X_{32}\u0026X_{33} \\\\ \\end{array} \\right)}_{X_{3×3}} \\otimes \\underbrace{\\left( \\begin{array}{cc} F_{11}\u0026F_{12} \\\\ F_{21}\u0026F_{22} \\\\ \\end{array} \\right)}_{F_{2×2}} $$ عشان نحسب $\\frac{\\partial O}{\\partial F}$ لازم نحسب الـgradient الخاص بـO بالنسبة لكل element في F، على سبيل المثال لو حسبنا الـgradient الخاص بـO بالنسبة إلى $F_{11}$: $$ O_{11} = X_{11}F_{11} + X_{12}F_{12} + X_{21}F_{21} + X_{22}F_{22} \\\\ ","date":"2022-02-28","objectID":"/%D9%83%D9%8A%D9%81-%D9%8A%D8%AA%D9%85-%D8%A7%D9%84%D9%80backpropagation-%D9%81%D9%8A-%D8%A7%D9%84%D9%80covolutional-neural-networks/:0:0","tags":["Deep Learning","Convolutions","CNN","Convolutional Neural Networks","Backpropagation","Neural Networks"],"title":"؟ConvNetsفي الـ Backpropagationكيف يتم تنفيذ الـ","uri":"/%D9%83%D9%8A%D9%81-%D9%8A%D8%AA%D9%85-%D8%A7%D9%84%D9%80backpropagation-%D9%81%D9%8A-%D8%A7%D9%84%D9%80covolutional-neural-networks/"},{"categories":["مما تعلمت"],"content":" الـVanishing Gradients هي أحد اكبر المشاكل الى أثرت على تطوّر الـneural networks لفترة طويلة، وبسببها كان تدريب الـdeep neural networks عملية صعبة وبتستغرق وقت كبير، لكن إيه السبب وراء المشكلة دى؟ Fig 1: Vanishing gradients. Source: Click here أحد أسباب المشكلة هو الـrandom weights initialization عن طريق normal distribution الـmean بتاعه صفر والـvariance واحد، استخدام الطريقة دى مع activation function زى sigmoid أو tanh كان يؤدي إلى إن الـoutput variance في كل layer يكون أكبر من الـinput variance، ده كان بيسبّب إن الـsigmoid في الـlayers الآخيرة توصل للـsaturation (لاحظ Figure 2)، فيصبح الـgradient صغير جداً أو بصفر، بالتالي في الـbackpropagation مش هقدر أعمل updates والـlearning هياخد وقت كبير وممكن يتوقف تماماً. Fig 2: Sigmoid function saturation regions. في Paper لـXavier Glorot، قال إن عشان نساوي الـinput variance والـoutput variance لازم يكون عدد الـinputs والـoutputs متساوي، لكنه قدم حل آخر يعوّض الشرط ده وهو الـGlorot initialization. ($fan_{out}$, $fan_{in}$ هو عدد الـinput neurons والـoutput neurons على الترتيب): Glorot Initialization\r\r$\\text{Where } fan_{avg} = (fan_{in} + fan_{out}/2), \\text{ initialize weights with:}$ $\\text{Normal Distribution with mean 0 and variance } \\sigma^2 = \\frac{1}{fan_{avg}}$ $\\text{Or a uniform distribution between -r and +r with } r = \\sqrt{\\frac{3}{fan_{avg}}}$ \r\r طيب المشكلة دى ظهرت بسبب الـsaturation في sigmoid و tanh، هل ممكن احلها لو استخدمت ReLU؟ الـReLU بتحل المشكلة دى في الجزء الموجب، لكنها بتقدم مشكلة جديدة بسبب الجزء السالب; لإن لو كان الـinput بتاعها سالب هيكون الـoutput صفر، وكمان الـgradient صفر، فـ مش هيحصل update للـweights، وبالتالي في الـstep الجاية هيظل الـouput والـgradient صفر، هنا يقال إن الـneurons are dead: لإن مش هيحصل updates عندهم على الإطلاق. الحل المباشر للمشكلة هو إننا نضيف قيمة للـfunction في الجزء السالب، فممكن نلجأ للـLeaky ReLU (موضحة في Figure 3); وفيها بنضيف ميل صغير جداً للـReLU في الجزء السالب، الميل ده إما يكون hyper parameter أنا الى بحدده، أو يكون رقم عشوائي في كل step (تُسمّى Randomized Leaky ReLU) وده بيضيف نوع من الـregularization على الـnetwork، أو يكون parameter بتتعلمه الـnetwork (تُسمّى Parametric Leaky ReLU) وده بيدي الـNetwork حرية أكبر، لكن ممكن يسبب overfitting لو الـdataset مش كبيرة بشكل كافي. Fig 3: Leaky ReLU activation function. وممكن نلجأ للـELU (موضّحة في Figure 4): وفيها الجزء السالب من الـReLU بياخد شكل الـexponential function، ورغم إنها ابطأ من الـReLU في الحساب، لكنها بتوصل للـconvergence في عدد خطوات أقل، لذلك في الـtraining بشكل عام بتكون اسرع، لكن في الـtesting فالـReLU بالتأكيد أسرع. Fig 4: ELU activation function. حتى الآن تعرضنا لبعض حلول الـVanishing gradients عن طريق الـGlorot initialization والـNon saturating activations زى الـReLU ومشتقاتها، لكن الحلول دى بتقيّد تصميم الـnetwork بالشروط الى بحطها على اختيار الـactivation وكمان بتعتمد بشكل كبير على الـinitialization. هل ممكن نتفادى القيود دى؟ أحد الأسباب الى ممكن تؤدى إلى unstable training هو الـInternal Covariate shift: ومعناه إن الـinput distribution الخاص بـlayer معيّنة بيتغير أثناء الـtraining بسبب الـweight update في الـlayers السابقة، الـshift المستمر ده بيأثر على كفاءة الـtraining لإن الـweight update التالي هيحاول يلافي تأثير التغيير في الـweights في الـlayers الى قبله عشان يقدر يوصل للـminimum cost. Fig 5: Covariate shift vs. internal covariate shift. Source: Click here الحل هنا هو إننا نحاول نثبت الـinput distribution بأكبر شكل ممكن، وده بيتم عن طريق الـBatch normalization: وفيها بنعمل standardization لناتج الـneurons قبل أو بعد الـactivation function بحيث يكون الـdistribution دايماً له نفس الـmean والـvariance بغض النظر عن الـbatch الحالية أو الـweights (لاحظ Figure 6). Fig 6: Batch normalization layer. Varying data distributions across batches are normalized. Source: Click here وبجانب الـstandardization كمان بنضيف scale \u0026 shift parameters بتتعلمهم الـnetwork عشان تقدر تحدد شكل الـdistribution المناسب لها في الـtraining، وبالتالي ممكن تلغي الـbatch norm بنفسها لو مش هتحتاجه. How to perform batch normalization\r\r$\\text{Input: Values of } x \\text{ over a mini-","date":"2021-12-14","objectID":"/%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9-%D9%85%D8%B4%D9%83%D9%84%D8%A9-%D8%A7%D9%84%D9%80vanishing-gradients/:0:0","tags":["Machine Learning","Deep Learning","Vanishing Gradient","Neural Networks","Batch Normalization","Keras","Leaky ReLU","ELU","Sigmoid","Tanh"],"title":"؟Vanishing gradientsكيف نتعامل مع مشكلة الـ","uri":"/%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9-%D9%85%D8%B4%D9%83%D9%84%D8%A9-%D8%A7%D9%84%D9%80vanishing-gradients/"},{"categories":["مما تعلمت"],"content":" الـGaussian Mixture models (GMM) هي عبارة عن probabilistic model بيقدر يعبر عن الـdata distribution وكأنه عبارة عن مجموعة gaussian models متجمعة مع بعض، وممكن نستخدمها كـclustering algorithm مشابه للـk-means . بس إزاي probabilistic model ممكن يعمل clustering للداتا أصلاً؟ الـGMM بيفترض إن الداتا متوزعة في أكتر من gaussian distribution، وهي دى الميزة الى انا بستغلها في الـclustering: انا ممكن اعتبر ان كل Gaussian من دول بيعبر عن cluster واحدة بس من الداتا. لاحظ Fig 1: انا افترضت إن عندي 4 clusters في الداتا ، فاستخدمت GMM فيه 4 Gaussians، فأصبح كل واحد منهم بيعبر عن cluster معينة. لاحظ Fig 1: انا افترضت إن عندي 4 clusters في الداتا ، فاستخدمت GMM فيه 4 Gaussians، فأصبح كل واحد منهم بيعبر عن cluster معينة. Fig 1: GMM clusters. the data consists of 4 cluster, therefore 4 gaussian components are used. Source: Click here طيب ما لو استخدمت الـk-means هلاقي نفس النتيجة، إيه المميز في الـGMM؟ في حالة الصورة الأولى كنت فعلاً هلاقي نتيجة مشابهة، لكن الإضافة الى بتقدمها الـGMM هو إن بقى عندي Probability: الـpoint دلوقتي مش محسوبة على cluster واحد بشكل قاطع، لكن دلوقتي اقدر احسب احتمال وجود نقطة معينة في أي cluster، ده اسمه soft clustering، على عكس الى بتعمله الـk-means وهو الـhard clustering. الميزة التانية والأكبر هي إن في حالة الـk-means، شكل الcluster بيتحدد بناءً على الـdistance metric الى اختارته في البداية، عكس الـGMM الى بيحدد شكل الـcluster فيه هو الـGaussian parameters الى بيتعلمها في الـtraining، وده بيبعدني عن مشكلة اختيار الـdistance metric المناسب في كل مرة، وكمان بيضيف للـmodel مرونة أكبر لإن ده بيسمحله يغير ابعاد الـcluster في كل dimension على حدة عن طريق الـcovariance matrix الى بيتعلمها، على عكس الـk-means الى هتلاقي ابعاد الـcluster ثابتة على كل الـdimensions. لاحظ الصورة التانية: في حالة الـk-means الـcluster هتاخد شكل ثابت بغض النظر عن شكل توزيع الـdata، على عكس الـGMM الى قدر يتعلم توزيع الداتا ويتعامل معاها بشكل جيد جداً. Fig 2: Kmeans clustering vs GMM clustering. Notice how GMM components fit the eliptical shape of the clusters. Source: Click here وزى ما قلنا في البداية، في الـGMM النقطة مش بتتحسب على cluster واحدة بس لكن بيكون لها probability لوجودها في كل cluster، أحد الـparameters الى بيتعلمها الـmodel هي في الـmixing coefficients وده بيحدد حجم كل gaussian بناءً على الـpoints density الموجودة فيه وبالتالي بيحدد الـprobability بتاعته. لاحظ\r\rلو فكرت فيها هتلاقي إنها منطقية: الـgaussian الى فيه نقط اكتر بيكون له وزن أكبر في إجمالي توزيع الداتا ،وخليك فاكر إن الـgaussians دى بتعبر عن توزيع الداتا في الأصل (probability distribution)، وبالتالي لازم يكون مجموع مساحاتهم يساوي 1 عشان يكون الـdistribution صحيح، لذلك بحتاج الـmixing coefficients عشان أحافظ على الخاصية دى.\r\r لو عندي نقطة واقعة بين two clusters هنتعامل معاها ازاي؟ الـMixing coefficient بيمنح الـGaussian الأكبر أفضلية على الـGaussian الصغير، لإن فيه عدد نقط أكتر، لذلك فيه احتمالية أكبر إن النقطة دى تكون تبعه، وده فعلاً الى حصل في النقطة البنفسجية القريبة من الـcluster الاخضر في Fig 2: رغم إنها أقرب للأخضر، بس احتمال وجودها في البنفسجي أكبر، لإن البنفسجي عنده points density أكبر. الملاحظة الأخيرة هي إن الـGMM مش algorithm مختلف كتير عن الـk-means، لكن ممكن تعتبره الحالة العامة من الـk-means. لمزيد من المعلومات: In Depth: Gaussian Mixture Models Machine Learning: Clustering \u0026 Retrieval ","date":"2021-12-07","objectID":"/%D9%83%D9%8A%D9%81-%D8%AA%D8%AD%D9%84-%D8%A7%D9%84%D9%80gaussian-mixture-models-%D9%85%D8%B4%D8%A7%D9%83%D9%84-%D8%A7%D9%84%D9%80k-means/:0:0","tags":["Machine Learning","Unsupervised Learning","Clustering","Kmeans","Gaussian Mixture Models","GMM","Probability"],"title":"؟K-meansمشاكل الـ Gaussian Mixture Modelsكيف تحل الـ","uri":"/%D9%83%D9%8A%D9%81-%D8%AA%D8%AD%D9%84-%D8%A7%D9%84%D9%80gaussian-mixture-models-%D9%85%D8%B4%D8%A7%D9%83%D9%84-%D8%A7%D9%84%D9%80k-means/"},{"categories":["مما تعلمت"],"content":" الـregularization هو أحد الحلول الشائعة لمشكلة الـoverfitting، بيتم عن طريق إضافة penalty مباشرة على الـparameters في الـcost function عشان أقلل الـmodel complexity، لكن لو لاحظت هتلاقي إن الـbias مش موجود في الـpenalty دى على الرغم من إنه أحد الـparameters الى الموديل بيتعلمها، ايه السبب؟ Fig 1: Linear regression with bias term (right) vs without bias term (left). Source: Click here خلينا نبدأ من ورا شوية: إحنا ليه بنحتاج bias term ؟ لإن الـbias بيمنح الموديل حرية أكبر في الحركة والتعلم، لاحظ Figure 1: في الحالتين استخدمت linear regression ، لكن على اليمين وصلت لموديل جيد جداً والـerror فيه قليل، أما على اليسار أستخدمت نفس الموديل لكن بدون bias وكانت النتيجة بعيدة تماماً عن الـdata، لإن لما بحط الـbias بصفر كده أنا أجبرت الموديل يمر بنقطة الأصل، وبالتالي ربطته بحالة واحدة بس في الغالب هتكون غير مناسبة للداتا الى معايا. الملاحظة التانية هى إن وجود الـbias أو عدمه مغيرش في الـmodel complexity على الإطلاق، في الحالتين الخط المستقيم متغيرش، الإختلاف الوحيد هو مكانه، ده معناه إن الـbias مش بيساهم في زيادة تعقيد الموديل، لكن بيمنحه حرية بيحتاجها في أوقات كتير، والميزة كمان إن ممكن الموديل بنفسه يتعلم إن الـbias صفر لو مش هيحتاجه. طيب إيه الى هيحصل لو عملت regularization للـbias؟ الـregularization بيجبر كل الـparameters إنها تاخد قيم صغيرة (في حالة الـL1 regularization ممكن يخليها بصفر كمان) بهدف إنه يقلل الـpenalty الإضافية ويوصل لـminimum cost، بالتالي لو ضفت الـbias معاهم هيكون مضطر يحطله قيم صغيرة جداً، وده عكس الى انا كنت عايزه لما ضفت الـbias: أنا كده سحبت منه الحرية الى كنت عايز اديهاله لما ضفت الـbias من البداية! والنتيجة إن في الغالب هتلاقي underfitting كبير في الموديل (لاحظ Figure 2). Fig 2: linear regression model with regularized bias vs with unregularized bias. Source: Click here لمزيد من المعلومات: Why does regularizing the bias lead to underfitting in neural networks? Why We Need Bias in Neural Networks ","date":"2021-11-30","objectID":"/%D9%84%D9%85%D8%A7%D8%B0%D8%A7-%D9%86%D8%B3%D8%AA%D8%AB%D9%86%D9%8A-%D8%A7%D9%84%D9%80bias-%D9%85%D9%86-%D8%A7%D9%84%D9%80regularization/:0:0","tags":["Machine Learning","Bias","Regularization","Linear Regression"],"title":"؟Regularizationمن الـ Biasلماذا نستثني الـ","uri":"/%D9%84%D9%85%D8%A7%D8%B0%D8%A7-%D9%86%D8%B3%D8%AA%D8%AB%D9%86%D9%8A-%D8%A7%D9%84%D9%80bias-%D9%85%D9%86-%D8%A7%D9%84%D9%80regularization/"},{"categories":["مما تعلمت"],"content":" من المشاكل الى قابلتها في الكورسات إن الـdataset أحياناً بتكون خالية من العيوب الى ممكن نلاقيها في أرض الواقع، وفي مجال الـclassification، فيه فرصة كبيرة إننا نتعامل مع imbalanced datasets لإن الأكيد إن مش كل الـclasses بتحدث بنفس النسبة وبالتالي الغير طبيعي هو إن لما أجمع data أشوف كل الـclasses بنفس الrate ، لكن ليه الـimbalance ده ممكن يسبب مشكلة أصلا؟ -- Fig 1: Example of an imbalanced dataset ممكن نطرح المشكلة بمثال: لنفترض إن عندي dataset فيها نتائج فحص عن ورم معين في الجسم، فيها 10 ألاف ريكورد عن بيانات مرضى مختلفين والمطلوب مني إن أنا ابني model يتنبأ بوجود الورم ده بناء على بيانات المريض، فأنا دربت موديل بسيط وصلت دقته 99%. نتيجة جيدة بالنسبة لأول تجربة صح؟ في البداية ممكن تتفق، لكن خلينا نلقي نظرة على الdata الأول: لما بصيت على الداتا لقيت إن فيه 100 ريكورد فقط من بين الـ10 آلاف عندهم الورم، والباقي نتايجهم سلبية ، بمعنى آخر: 99% من المرضى الموجودين في الداتا مفيش عندهم ورم. تخيل معايا بقى إن أنا عملت موديل بيفترض إن كل المرضى مفيش عندهم ورم، يعني بيتنبأ إن كل العينات سلبية، الموديل الساذج ده قدر يوصل لـ99% accuracy من غير ما يعمل حاجة! يبقى هنا الـaccuracy أصبحت معيار غير صحيح لنتايج الموديل بتاعي. ليه مقدرش أعتمد على الـaccruacy في مشكلة زى دى؟ $$ Accuracy = \\frac{TP + TN}{TP + FP + TN + FN} $$ $$ TP: True Postive \\hspace{1mm} | \\hspace{1mm} FP: False Positive \\hspace{1mm} | \\hspace{1mm} TN: True Negative \\hspace{1mm} | \\hspace{1mm} FN: False Negative $$ لإن الـaccuracy بتهتم بحساب نسبة الـTrue positive والـTrue negative، في الحالة الى عندي هنا الـNegative يمثّل 99% من الـdata، وبالتالي حتى لما ضحيت بجزء الـtrue positive لم أفقد أي جزء يذكر من الـaccuracy، فكان ده السبب إن الـaccuracy كانت عالية جداً بالنسبة لـmodel حرفياً متعلمش أي حاجة. طب إيه الحل؟ إزاي أقدر احكم على مدى صحة توقعات الموديل في الحالة دى؟ في المشكلة الى عندي، تكلفة إن المريض يبقى عنده ورم وأنا اتنبأ إن معندوش كبيرة جداً: الورم ممكن يكلفه حياته، فبالتالي لازم أختار measure بيتأثر تحديداً بنسبة الـFalse negative وهو الـrecall، لو حسبت الـrecall للموديل البسيط الى عندي هيساوي 0% وهنا تكون النتيجة منطقية. $$ Recall = \\frac{TP}{TP + FN} $$ في حالة أخرى ممكن تكون تكلفة الـFalse positive كبيرة وعندها لازم أختار measure بيتأثر بيه وهو الـPrecision: $$ Precision = \\frac{TP}{TP + FP} $$ ولو محتاج أتابع الأتنين مع بعض يبقى أختار الـF1 score وهو أفضل معيار ممكن استخدمه في حالة التعامل مع Imbalanced data، لإنه بيتأثر بنسبة الـFalse positive والـFalse negative في نتائج الموديل. $$ F_{1} = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall} $$ بعد ما عرفت الـmeasure الى أقدر احكم بيه على نتايج الموديل، الخطوة التالية هي إننا نعمل موديل بيتعلم بكفاءة من الـimbalanced data وبيأدي بشكل جيد سواء على الـmajority class (الى بتمثّل غالبيّة الـdataset) أو الـminority class، طب ليه الـimbalance ممكن يسببلي مشكلة هنا؟ في مرحلة الtraining، الموديل بيهدف إنه يوصل للـparameters الى الـcost عندها أقل ما يمكن، خلال المرحلة دى (ولإن الـmajority class تمثّل غالبية الصفوف في الداتا)، هتلاقي إن معظم الـupdates رايحة ناحية تحسين نتائج الموديل على الـmajority class ، لإن فرصة الـmissclassification فيها أعلى بكتير، وده معناه إنها بتساهم في الـcost بشكل اكبر بكتير من الـminority class، فبالتالي هينتج موديل عنده bias ناحية الـmajority class وبيأدي فيها بشكل أفضل بكتير من الـminority class. Fig 2: مثال على نتائج model بعد تدريبه على imbalanced dataset، لاحظ نسبة الخطأ الكبيرة في الـminority class Source: Click here أحد الطرق الى ممكن تحل مشكلة الـclass imbalance هي إننا نخلق balance بنفسنا عن طريق الـdata resampling وده ممكن يتم بأكتر من طريقة: الطريقة الأولى هي الـRandom Under-sampling: عندك class مسيطر عالداتا ؟ بسيطة: احذف صفوف منه عشوائياً لحد ما يتساوى بالـclass التاني. حل بسيط لكنه غير منطقي، الناس بتحاول تجمع أكبر قدر ممكن من الداتا، وانت رايح تحذفها؟! وهو فعلاً مش أفضل حل لإن حتى لو حلّيت مشكلة الـimbalance هتدخل في مشكلة تانية لإنك فقدت جزء كبير من الداتا ،وكمان ممكن الـsample الصغيرة الى حافظت عليها تكون biased ومش بتعبر عن الـmajority بشكل كويس ،وبالتالي مش هتلاقي نتيجة جيدة. Fig 3: Random Undersampling Vs. Random Oversampling الطريقة التانية هي الـRandom Over-sampli","date":"2021-11-20","objectID":"/imbalanced-datasets-%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9/:0:0","tags":["Machine Learning","Data Science","Data Resampling","SMOTE","Cost-Sensitive Training","Data Analysis","Accurace","Precision","Recall","F1 Score"],"title":"؟Imbalanced Datasets كيف نتعامل مع","uri":"/imbalanced-datasets-%D9%83%D9%8A%D9%81-%D9%86%D8%AA%D8%B9%D8%A7%D9%85%D9%84-%D9%85%D8%B9/"},{"categories":["مما تعلمت"],"content":" ReLU هو اختصار Rectified Linear Unit وهي واحدة من أكثر الـactivation functions المستخدمة في الـNeural networks، رغم إن اسمها يحتوى على كلمة linear لكنها non linear function، وده واضح رياضياً وحتى من الرسم بتاعها، لكن ليه بتقدر تنافس الـactivation functions الأخرى المكوّنة من smooth curves رغم إنها حرفياً عبارة عن خطين بس؟ -- $$ ReLU=max(0,x) $$ Fig 1: ReLU Graph ميزة الـReLU الكبرى مش بتظهر لما أستخدم واحدة بس منها، لكن بتكون واضحة لما أجمع شوية دوال ReLU كتير مع بعض، نقطة الانكسار الموجودة بين جزئين دالة الـReLU بتقدر تقرّبلك مجموعة الخطوط الكتيرة دى من أي منحنى أنت عايزه عن طريق إنها بتتيح لك تكسر الخط المستقيم في أي مكان انت عايزه (أو المكان الى الـneural network بتتعلمه). لاحظ الصورة التالية: لما استخدمت ReLU واحدة بس مقدمتش اختلاف كبير عن الـstraight line، لكن لما بدأت اعمل nesting واجمعهم مع بعض بدأت أكوّن شكل جديد مقدرتش أوصله لما جمعت الـstraight lines مع بعض. Fig 2: ReLU vs. Linear function طيب هل هي فعلاً تقدر توصل لمنحنيات صعبة زى باقي الـactivation function؟ الإجابة القصيرة: نعم، وده واضح من خلال استخدامها الشائع والواسع في كل مجالات الـdeep learning، لاحظ الصورة التالية: عن طريق استخدام أكتر من ReLU function قدرت أوصل لشكل تقريبي من منحنى $x^3+x^2-x-1$ Fig 3: We can use many ReLUs to approximate complex functions Source: Click here وبالنسبة للـNeural networks، في الصورة التالية نقدر نلاحظ إن neural network بتستخدم ReLU كـActivation function وصلت لمنحنى قريب من المنحنى التانج عن neural network بتستخد $tanh$ في نفس عدد الـepoch Fig 4: كل network تحتوي 3 hidden layers، كل منهم يحتوى 3 neurons Source: Click here طيب ما الـtanh وصلت لـsmooth curve وعملت نتيجة كويسة بردو، ليه اروح للـReLU؟ هنا تيجي ميزة الـReLU التانية والى بتديلها أفضلية كبيرة عن الـtanh: إنها very computationally efficient، هي في الآخر عبارة عن خط وتفاضلها ثابت، على عكس الـtanh الى فيها exponentials وتفاضلها متغير. لمزيد من المعلومات Finally, an intuitive explanation of why ReLU works Can neural networks solve any problem? ","date":"2021-11-13","objectID":"/%D9%84%D9%8A%D9%87-%D8%A3%D8%B5%D8%A8%D8%AD%D8%AA-%D8%A7%D9%84%D9%80relu-%D8%A7%D9%84%D8%AE%D9%8A%D8%A7%D8%B1-%D8%A7%D9%84%D8%B4%D8%A7%D8%A6%D8%B9-%D9%84%D9%84%D9%80activation-function/:0:0","tags":["Neural Networks","Deep Learning"],"title":"؟Activation functionsالخيار الشائع للـ ReLUليه أصبحت الـ","uri":"/%D9%84%D9%8A%D9%87-%D8%A3%D8%B5%D8%A8%D8%AD%D8%AA-%D8%A7%D9%84%D9%80relu-%D8%A7%D9%84%D8%AE%D9%8A%D8%A7%D8%B1-%D8%A7%D9%84%D8%B4%D8%A7%D8%A6%D8%B9-%D9%84%D9%84%D9%80activation-function/"},{"categories":["مما تعلمت"],"content":" الهدف النهائي الى أنا عايزه من الـneural network هو انها تعبر بشكل تقريبي عن العلاقة ما بين $input \\hspace{1mm} (X)$ و $target$ او $output \\hspace{1mm} (y)$، بمعنى آخر أنا عايزها تـapproximate دالة $f$ حيث $f(x)=y$. هل الـneural networks تقدر تحقق العلاقة دى؟ نظرية الـuniversal approximation بتقول إن اي neural network فيها hidden layer واحدة فقط فيها عدد معيّن من الـneurons، تقدر تعبر عن أي continuous function انت عايزها ولكن لازم تاخد في الاعتبار بعض الشروط، أحد الشروط دى هى الـnon linear activation function. طيب ليه مش هقدر أحقق الـuniversal approximation من غير الـnon linear activation function؟ لإن من غيرها فكل الحسابات الى بتحصل داخل الـneural network ناتجة عن عمليات linear، كلها عمليات ضرب وجمع، لذلك المحصلة النهائية من كل ده هي إن الـneural network مش هتقدر تعبر عن أي حاجة اكتر تعقيداً من linear relationship. طيب هل لو زودت أكتر من hidden layer واحدة هقدر أوصل لـnon linear relationship؟ إضافة hidden layer تانية كتير لا يعني إن انا بضيف non linearity في العلاقة، في الحقيقة كل الـhidden layers دى بتعمل linear transormations متتابعة مش أكتر، والمفاجأة إن كل الـhidden layers الى أنا ضفتها ممكن أستعوض عنهم بـhidden layer واحدة بس تؤدي كل الـlinear transformations دى مرة واحدة، والمفاجأة التانية هى إن كل الـneurons الموجودة في الـhidden layer الواحدة دى ممكن استعوض عنهم بـneuron واحد بس. تفتكر كان إيه اسم الـmodel المكوّن من neuron واحد فقط ومفيش فيه non linear activation function؟ أيوة هو الـlinear regression. فبالتالي أي neural network لا تستخدم activation function قدرتها لا تتعدى قدرة اي linear regression model بسيط. لمزيد من المعلومات: You Don’t Understand Neural Networks Until You Understand the Universal Approximation Theorem Neural Networks and the Universal Approximation Theorem Everything you need to know about “Activation Functions” in Deep learning models ","date":"2021-11-09","objectID":"/%D9%84%D9%8A%D9%87-%D8%A8%D9%86%D8%AD%D8%AA%D8%A7%D8%AC-non-linear-activation-functions-%D9%81%D9%8A-%D8%A7%D9%84%D9%80neural-networks/:0:0","tags":["Machine Learning","Deep Learning","Neural Networks"],"title":"؟Neural networksفي الـ Non-linear activation functions ليه بنحتاج","uri":"/%D9%84%D9%8A%D9%87-%D8%A8%D9%86%D8%AD%D8%AA%D8%A7%D8%AC-non-linear-activation-functions-%D9%81%D9%8A-%D8%A7%D9%84%D9%80neural-networks/"}]